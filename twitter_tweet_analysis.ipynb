{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import tweepy as tw\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add your keys\n",
    "consumer_key= ''\n",
    "consumer_secret= ''\n",
    "access_token= ''\n",
    "access_token_secret= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"#farmers-filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=search_term,\n",
    "                   lang=\"en\",\n",
    "                   since='2021-01-04').items(1000)\n",
    "\n",
    "all_tweets = [tweet.text for tweet in tweets]\n",
    "\n",
    "all_tweets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Enter your keys/secrets as strings in the following fields\n",
    "credentials = {}\n",
    "credentials['CONSUMER_KEY'] = ''\n",
    "credentials['CONSUMER_SECRET'] = ''\n",
    "credentials['ACCESS_TOKEN'] = ''\n",
    "credentials['ACCESS_SECRET'] = ''\n",
    "\n",
    "# Save the credentials object to file\n",
    "with open(\"twitter_credentials.json\", \"w\") as file:\n",
    "    json.dump(credentials, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n",
    "\n",
    "# Create our query\n",
    "query = {'q': '#farmers',\n",
    "        'result_type': 'popular',\n",
    "        'count': 100,\n",
    "       'lang': 'en',\n",
    "        }\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# Search tweets\n",
    "dict_ = {'TwitterUser': [], 'Date': [], 'Tweet Text': [], 'Likes': []}\n",
    "for status in python_tweets.search(**query)['statuses']:\n",
    "    dict_['TwitterUser'].append(status['user']['screen_name'])\n",
    "    dict_['Date'].append(status['created_at'])\n",
    "    dict_['Tweet Text'].append(status['text'])\n",
    "    dict_['Likes'].append(status['favorite_count'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure data in a pandas DataFrame for easier manipulation\n",
    "print(query)\n",
    "df = pd.DataFrame(dict_)\n",
    "df.sort_values(by='Likes', inplace=True, ascending=False)\n",
    "display(HTML(df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TWITTER STREAMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "import csv\n",
    "\n",
    "# Filter out unwanted data\n",
    "def process_tweet(tweet):\n",
    "    d = {}\n",
    "    d['hashtags'] = [hashtag['text'] for hashtag in tweet['entities']['hashtags']]\n",
    "    d['text'] = tweet['text']\n",
    "    d['user'] = tweet['user']['screen_name']\n",
    "    d['user_loc'] = tweet['user']['location']\n",
    "    return d\n",
    "    \n",
    "    \n",
    "# Create a class that inherits TwythonStreamer\n",
    "class MyStreamer(TwythonStreamer):     \n",
    "\n",
    "    # Received data\n",
    "    def on_success(self, data):\n",
    "\n",
    "        # Only collect tweets in English\n",
    "        #if data['lang'] == 'en':\n",
    "            tweet_data = process_tweet(data)\n",
    "            self.save_to_csv(tweet_data)\n",
    "\n",
    "    # Problem with the API\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()\n",
    "        \n",
    "    # Save each tweet to csv file\n",
    "    def save_to_csv(self, tweet):\n",
    "        with open(r'Tweets_saved.csv', 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(list(tweet.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate from our streaming class\n",
    "stream = MyStreamer(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'], \n",
    "                    creds['ACCESS_TOKEN'], creds['ACCESS_SECRET'])\n",
    "# Start the stream\n",
    "stream.statuses.filter(track='#farmers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT STEPS LOOKING AT CSV FILE\n",
    "import pandas as pd\n",
    "tweets = pd.read_csv(\"Tweets_saved.csv\",header=None)\n",
    "tweets=tweets[:]\n",
    "tweets=tweets.drop_duplicates() ## drop duplicate rows\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "tweets = pd.read_csv(\"saved_tweets.csv\",header=None)\n",
    "\n",
    "# Extract hashtags and put them in a list\n",
    "list_hashtag_strings = [entry for entry in tweets[0]]\n",
    "list_hashtag_lists = ast.literal_eval(','.join(list_hashtag_strings))\n",
    "hashtag_list = [ht.lower() for list_ in list_hashtag_lists for ht in list_]\n",
    "\n",
    "# Count most common hashtags\n",
    "counter_hashtags = Counter(hashtag_list)\n",
    "counter_hashtags.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "clean_tweets_nsw = pd.DataFrame(counter_hashtags.most_common(20),\n",
    "                             columns=['words', 'count'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot horizontal bar graph\n",
    "clean_tweets_nsw.sort_values(by='count').plot.barh(x='words',\n",
    "                      y='count',\n",
    "                      ax=ax,\n",
    "                      color=\"purple\")\n",
    "\n",
    "ax.set_title(\"Hastags Trending on Twitter\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import gmplot\n",
    "import numpy as np\n",
    "\n",
    "lists=['india', 'canada', 'earth', 'worldwide', 'us', 'united states', 'hell', 'twitter','uk']\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"aj-application\")\n",
    "\n",
    "# Go through all tweets and add locations to 'coordinates' dictionary\n",
    "coordinates = {'latitude': [], 'longitude': []}\n",
    "for count, user_loc in enumerate(tweets[3]):\n",
    "    try:\n",
    "        #if user_loc.isnull()==FALSE:\n",
    "        #print(user_loc is np.nan)\n",
    "        if user_loc is np.nan:\n",
    "            pass\n",
    "        if user_loc.lower() in lists:\n",
    "            pass\n",
    "        else:\n",
    "            location = geolocator.geocode(user_loc)\n",
    "            #print(user_loc)\n",
    "\n",
    "        # If coordinates are found for location\n",
    "        if location:\n",
    "            coordinates['latitude'].append(location.latitude)\n",
    "            coordinates['longitude'].append(location.longitude)\n",
    "            \n",
    "    # If too many connection requests\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and center a GoogleMapPlotter object to show our map\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(30, 0, 3,apikey='apikey')\n",
    "\n",
    "# Insert points on the map passing a list of latitudes and longitudes\n",
    "gmap.heatmap(coordinates['latitude'], coordinates['longitude'] ,max_intensity=300,radius=20)\n",
    "\n",
    "# Save the map to html file\n",
    "gmap.draw(\"python_heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT STEPS LOOKING AT CSV FILE\n",
    "import pandas as pd\n",
    "tweets = pd.read_csv(\"saved_tweets.csv\",header=None)\n",
    "tweets=tweets[:]\n",
    "tweets=tweets.drop_duplicates() ## drop duplicate rows\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "tweets = pd.read_csv(\"saved_tweets.csv\",header=None)\n",
    "\n",
    "# Extract hashtags and put them in a list\n",
    "list_hashtag_strings = [entry for entry in tweets[0]]\n",
    "list_hashtag_lists = ast.literal_eval(','.join(list_hashtag_strings))\n",
    "hashtag_list = [ht.lower() for list_ in list_hashtag_lists for ht in list_]\n",
    "\n",
    "# Count most common hashtags\n",
    "counter_hashtags = Counter(hashtag_list)\n",
    "#counter_hashtags.most_common(50)\n",
    "common=counter_hashtags.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for plotting images & adjusting colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into dict\n",
    "common= dict(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#font=\"gargi.ttf\"\n",
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(background_color='black', width = 400, height=300, margin=8)\n",
    "\n",
    "wc.fit_words(common)\n",
    "wc.to_file('wc1.png')\n",
    "\n",
    "plt.figure(figsize=[25,25])\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "clean_tweets_nsw = pd.DataFrame(counter_hashtags.most_common(30),\n",
    "                             columns=['words', 'count'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot horizontal bar graph\n",
    "clean_tweets_nsw.sort_values(by='count').plot.barh(x='words',\n",
    "                      y='count',\n",
    "                      ax=ax,\n",
    "                      color=\"purple\")\n",
    "\n",
    "ax.set_title(\"Hastags Trending on Twitter #farmersprotest\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_hashtags.most_common(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
